{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEET2574 | Big Data for Engineering\n",
    "## Assignment 2: MongoDB and Spark\n",
    "Author: Tran Manh Cuong - s3974735\n",
    "\n",
    "Instructor: Dr. Arthur Tang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets from CSV files into MongoDB collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from coteq_electricity_2018.csv has been loaded to collection Electricity_2018.\n",
      "Data from stedin_electricity_2018.csv has been loaded to collection Electricity_2018.\n",
      "Data from westland-infra_electricity_2018.csv has been loaded to collection Electricity_2018.\n",
      "Data from coteq_electricity_2019.csv has been loaded to collection Electricity_2019.\n",
      "Data from stedin_electricity_2019.csv has been loaded to collection Electricity_2019.\n",
      "Data from westland-infra_electricity_2019.csv has been loaded to collection Electricity_2019.\n",
      "Data from coteq_electricity_2020.csv has been loaded to collection Electricity_2020.\n",
      "Data from stedin_electricity_2020.csv has been loaded to collection Electricity_2020.\n",
      "Data from westland-infra_electricity_2020.csv has been loaded to collection Electricity_2020.\n",
      "Data from coteq_gas_2018.csv has been loaded to collection Gas_2018.\n",
      "Data from stedin_gas_2018.csv has been loaded to collection Gas_2018.\n",
      "Data from westland-infra_gas_2018.csv has been loaded to collection Gas_2018.\n",
      "Data from coteq_gas_2019.csv has been loaded to collection Gas_2019.\n",
      "Data from stedin_gas_2019.csv has been loaded to collection Gas_2019.\n",
      "Data from westland-infra_gas_2019.csv has been loaded to collection Gas_2019.\n",
      "Data from coteq_gas_2020.csv has been loaded to collection Gas_2020.\n",
      "Data from stedin_gas_2020.csv has been loaded to collection Gas_2020.\n",
      "Data from westland-infra_gas_2020.csv has been loaded to collection Gas_2020.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ELECTRICITY_DIR = \"./data/Electricity\"\n",
    "GAS_DIR = \"./data/Gas\"\n",
    "# You can replace the URI with your own MongoDB URI\n",
    "MONGODB_URI = \"mongodb+srv://cuongtran:cuongtran123@cluster0.5zjcy.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "# MongoDB connection\n",
    "client = pymongo.MongoClient(MONGODB_URI)\n",
    "db = client[\"main\"]\n",
    "\n",
    "\n",
    "# Data mapping for collections\n",
    "collections_mapping = {\n",
    "    \"Electricity\": {\n",
    "        \"2018\": [\"coteq_electricity_2018.csv\", \"stedin_electricity_2018.csv\", \"westland-infra_electricity_2018.csv\"],\n",
    "        \"2019\": [\"coteq_electricity_2019.csv\", \"stedin_electricity_2019.csv\", \"westland-infra_electricity_2019.csv\"],\n",
    "        \"2020\": [\"coteq_electricity_2020.csv\", \"stedin_electricity_2020.csv\", \"westland-infra_electricity_2020.csv\"]\n",
    "    },\n",
    "    \"Gas\": {\n",
    "        \"2018\": [\"coteq_gas_2018.csv\", \"stedin_gas_2018.csv\", \"westland-infra_gas_2018.csv\"],\n",
    "        \"2019\": [\"coteq_gas_2019.csv\", \"stedin_gas_2019.csv\", \"westland-infra_gas_2019.csv\"],\n",
    "        \"2020\": [\"coteq_gas_2020.csv\", \"stedin_gas_2020.csv\", \"westland-infra_gas_2020.csv\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check if a collection exists in MongoDB\n",
    "def is_collection_exist(collection_name):\n",
    "    return collection_name in db.list_collection_names()\n",
    "\n",
    "# Load data into MongoDB\n",
    "def load_data_to_mongodb(database, directory, year, file_list):\n",
    "    collection_name = f\"{database}_{year}\"\n",
    "    if is_collection_exist(collection_name):\n",
    "        print(f\"Collection {collection_name} already exists. Skipping data load process.\")\n",
    "        return\n",
    "    \n",
    "    collection = db[collection_name]\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        records = df.to_dict(orient=\"records\")\n",
    "        collection.insert_many(records)\n",
    "        print(f\"Data from {file_name} has been loaded to collection {collection_name}.\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    for database, years in collections_mapping.items():\n",
    "        for year, file_list in years.items():\n",
    "            if database == \"Electricity\":\n",
    "                load_data_to_mongodb(database, ELECTRICITY_DIR, year, file_list)\n",
    "            elif database == \"Gas\":\n",
    "                load_data_to_mongodb(database, GAS_DIR, year, file_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1A: How many collections do you have? Why?\n",
    "The MongoDB database contains a total of 6 collections, categorized based on type of data (Electricity, Gas) and year (2018, 2019, 2020):\n",
    "- Electricity collections: Electricity_2018, Electricity_2019, Electricity_2020\n",
    "- Gas collections: Gas_2018, Gas_2019, Gas_2020\n",
    "\n",
    "This design choice allows targeted querying and manipulation during data ingestion and cleaning in Task 2. By having distinct collections for each category and year, we can streamline the transformation pipeline, as each collection can be processed individually or combined as needed. Furthermore, this structure supports scalable data management. If new data for additional years or companies becomes available, it can easily be incorporated into separate collections without affecting the existing ones.\n",
    "\n",
    "Another reason for this design is to simplify model training and tracking in Task 3. Since the task requires using 2018 and 2019 data for training and 2020 for testing, the separate collections make it straightforward to load and partition data for machine learning pipelines. Additionally, visualizations in Task 4 benefit from this schema as it allows flexibility to aggregate data across years or focus on specific time frames and data types.\n",
    "\n",
    "![data-collections.png](./assets/data-collections.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
